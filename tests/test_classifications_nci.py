# %%
import time

# Change directory to this repo - this should work on gadi or locally via python or jupyter.
import os, sys
repo_name = "shelterbelts"
if os.path.expanduser("~").startswith("/home/"):  # Running on Gadi
    repo_dir = os.path.join(os.path.expanduser("~"), f"Projects/{repo_name}")
elif os.path.basename(os.getcwd()) != repo_name:  # Running in a jupyter notebook 
    repo_dir = os.path.dirname(os.getcwd())       
else:                                             # Already running from root of this repo. 
    repo_dir = os.getcwd()
src_dir = os.path.join(repo_dir, 'src')
os.chdir(src_dir)
sys.path.append(src_dir)
print(src_dir)

# I haven't yet setup environments using pdal or lidr for creating tifs from .laz files on NCI
from shelterbelts.classifications.sentinel_nci import download_ds2
from shelterbelts.classifications.merge_inputs_outputs import tile_csv
from shelterbelts.classifications.neural_network import neural_network
# from shelterbelts.classifications.predictions_batch import tif_prediction_ds


data_dir = '/g/data/xe2/cb8590/Nick_Aus_treecover_10m'
stub = 'g2_26729_binary_tree_cover_10m'
sample_tif = f'{data_dir}/{stub}.tiff'
outdir = '/scratch/xe2/cb8590/tmp'
drop_columns = ['x', 'y', 'tile_id', 'points', 'spatial_ref']
sentinel_tile =  f'{outdir}/{stub}_ds2_2020.pkl'  # Generated by download_ds2
training_file = os.path.join(outdir, f'{stub}_ds2_df_r4_s2.csv') # Generated by tile_csv

def test_basic():
    """Basic tests for each of the files"""
    download_ds2(sample_tif, start_date="2020-01-01", end_date="2021-01-01", outdir=outdir)
    tile_csv(sentinel_tile, tree_file=sample_tif, outdir=outdir, radius=4, spacing=1)
    neural_network(training_file, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.001, epochs=20, batch_size=32, random_state=1, stratification_columns=['tree_cover'], train_frac = 0.7)

def test_sentinel():
    """More comprehensive tests for sentinel imagery from the NCI Datacube: 2x year ranges"""
    download_ds2(sample_tif, start_date="2020-06-01", end_date="2021-06-01", outdir=outdir)
    # 10 secs using the NCI datacube compared to 5 mins using the DEA STAC API
    
def test_merging():
    """More comprehensive tests for the merging: 2x radius, 2x spacing"""
    tile_csv(sentinel_tile, tree_file=sample_tif, outdir=outdir, radius=4, spacing=10, verbose=False)
    tile_csv(sentinel_tile, tree_file=sample_tif, outdir=outdir, radius=1, spacing=10, verbose=False)
    tile_csv(sentinel_tile, tree_file=sample_tif, outdir=outdir, radius=4, spacing=2, verbose=False)
    # 7 secs for the spacing=1
    
def test_neural_network_known():
    """"More comprehensive tests for the neural network: 2x learning rates, 2x batch_sizes, 2x random states, 2x stratified, 2x epochs, 2x train_fracs, 2x limits"""
    filename = training_file
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.001, epochs=10, batch_size=32, random_state=1, stratification_columns=['tree_cover'], train_frac = 0.7, limit=1000)
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.001, epochs=10, batch_size=32, random_state=1, stratification_columns=['tree_cover'], train_frac = 0.7, limit=None)
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.01, epochs=20, batch_size=32, random_state=1, stratification_columns=['tree_cover'], train_frac = 0.7, limit=None)
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.01, epochs=20, batch_size=16, random_state=1, stratification_columns=['tree_cover'], train_frac = 0.7, limit=None)
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.01, epochs=20, batch_size=16, random_state=0, stratification_columns=['tree_cover'], train_frac = 0.7, limit=None)
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.01, epochs=20, batch_size=16, random_state=0, stratification_columns=[], train_frac = 0.7, limit=None)
    neural_network(filename, outdir, stub, output_column='tree_cover', drop_columns=drop_columns, learning_rate=0.01, epochs=20, batch_size=16, random_state=0, stratification_columns=[], train_frac = 0.8, limit=None)

    # These example accuracies are quite high because the training data is just from a single 2km x 2km area. 

    

# %%
# Predicting new locations
def test_neural_network_unknown():
    """More comprehensive tests for using the model to predict unseen data"""
    tif_prediction_ds(ds, stub, outdir,  model, scaler, savetif)



# %%

if __name__ == '__main__':
    print("testing classifications on NCI")
    start = time.time()
    
    test_basic()
    test_sentinel()
    test_merging()
    test_neural_network_known()

    print(f"tests successfully completed in {time.time() - start} seconds")


# %%

#!/bin/bash
#PBS -N neural_network
#PBS -l mem=32GB
#PBS -l ncpus=4
#PBS -l jobfs=1GB
#PBS -P xe2
#PBS -l walltime=05:00:00
#PBS -l storage=gdata/xe2+gdata/v10+gdata/ka08
#PBS -q normal
#PBS -j oe


# Print out input variables to the error log
echo "Starting neural_network.pbs"

# Change working directory
wd=/home/147/cb8590/Projects/shelterbelts/src/shelterbelts/classifications
cd $wd

# Setup DEA environment modules for running the Python script
module use /g/data/v10/public/modules/modulefiles
module load dea/20231204  # using this version to match my predictions.pbs (needs old tensorflow, load_ard, gpd.read_file)
# source /g/data/xe2/cb8590/miniconda/etc/profile.d/conda.sh
# conda activate /g/data/xe2/cb8590/miniconda/envs/shelterbelts

# training_stub=df_matching_year
# training_stub=df_previous_2years
# training_stub=df_previous_year
# training_stub=df_next_year

# training_stub=df_all_years
# training_stub=df_previous_5years
# training_stub=df_matching2
# training_stub=df_matching_4326
# training_stub=df_matching_koppen
training_stub=df_4326_CFa

seed=0
echo "dea/20231204 NN Training stub: $training_stub"

# Run the script
# python3 neural_network.py /scratch/xe2/cb8590/Tas_csv/TEST_preprocessed.feather --outdir /scratch/xe2/cb8590/Tas_tifs
# python3 random_forest.py /scratch/xe2/cb8590/Tas_csv/TEST_preprocessed.feather --outdir /scratch/xe2/cb8590/Tas_tifs --stub 'RF'

# python3 random_forest.py /scratch/xe2/cb8590/Nick_training_lidar_year/$training_stub.feather --outdir /scratch/xe2/cb8590/Nick_training_lidar_year --stub RF_${training_stub}_keepxy --random_state $seed --drop_columns spatial_ref tile_id year start_date end_date
python3 neural_network.py /scratch/xe2/cb8590/Nick_training_lidar_year/$training_stub.feather --outdir /scratch/xe2/cb8590/Nick_training_lidar_year --stub NN_${training_stub} --drop_columns spatial_ref tile_id year start_date end_date crs Koppen
